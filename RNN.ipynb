{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitriySechkin/ds-learning-sb/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "in0PyicHhZDG"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "73ieMA485Tme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ec6a7e9-b58e-4c7e-dd92-5f492d3469dd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'drive/My Drive/'\n",
        "train_lang = 'en2'"
      ],
      "metadata": {
        "id": "Os4tVkvmkTIp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class DatasetSeq(Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, train_lang='en'):\n",
        "\n",
        "\t      #open file\n",
        "        with open(data_dir + train_lang + '.train', 'r') as f:\n",
        "          self.dataset = f.read().split('\\n\\n')\n",
        "\n",
        "        # delete extra tag markup\n",
        "        self.dataset = [x for x in self.dataset if not '_ ' in x]\n",
        "\n",
        "\t    #init vocabs of tokens for encoding {<str> token: <int> id}\n",
        "        self.target_vocab = {} # {p: 1, a: 2, r: 3, pu: 4}\n",
        "        self.word_vocab = {} # {cat: 1, sat: 2, on: 3, mat: 4, '.': 5}\n",
        "        self.char_vocab = {} # {c: 1, a: 2, t: 3, ' ': 4, s: 5}\n",
        "\n",
        "        # Cat sat on mat. -> [1, 2, 3, 4, 5]\n",
        "        # p    a  r  p pu -> [1, 2, 3, 1, 4]\n",
        "        # chars  -> [1, 2, 3, 4, 5, 2, 3, 4]\n",
        "\n",
        "\t    #init encoded sequences lists (processed data)\n",
        "        self.encoded_sequences = []\n",
        "        self.encoded_targets = []\n",
        "        self.encoded_char_sequences = []\n",
        "        # n=1 because first value is padding\n",
        "        n_word = 1\n",
        "        n_target = 1\n",
        "        n_char = 1\n",
        "\n",
        "        for line in self.dataset:\n",
        "            sequence = []\n",
        "            target = []\n",
        "            chars = []\n",
        "            for item in line.split('\\n'):\n",
        "                if item != '':\n",
        "                    word, label = item.split(' ')\n",
        "\n",
        "                    if self.word_vocab.get(word) is None:\n",
        "                        self.word_vocab[word] = n_word\n",
        "                        n_word += 1\n",
        "                    if self.target_vocab.get(label) is None:\n",
        "                        self.target_vocab[label] = n_target\n",
        "                        n_target += 1\n",
        "                    for char in word:\n",
        "                        if self.char_vocab.get(char) is None:\n",
        "                            self.char_vocab[char] = n_char\n",
        "                            n_char += 1\n",
        "                    sequence.append(self.word_vocab[word])\n",
        "                    target.append(self.target_vocab[label])\n",
        "                    chars.append([self.char_vocab[char] for char in word])\n",
        "            self.encoded_sequences.append(sequence)\n",
        "            self.encoded_targets.append(target)\n",
        "            self.encoded_char_sequences.append(chars)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoded_sequences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return {\n",
        "            'data': self.encoded_sequences[index], # [1, 2, 3, 4, 6] len=5\n",
        "            'char': self.encoded_char_sequences[index],# [[1,2,3], [4,5], [1,2], [2,6,5,4], []] len=5\n",
        "            'target': self.encoded_targets[index], #  (1)\n",
        "        }"
      ],
      "metadata": {
        "id": "SI8UCZuy7hTK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = DatasetSeq(data_dir, train_lang)"
      ],
      "metadata": {
        "id": "dhJuBtoz7f43"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sqyiSPgfU3ry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#padding\n",
        "# seq1 = [1, 2, 3, 4]\n",
        "# seq2 = [9, 7, 6, 4, 3, 7, 5]\n",
        "# pad seq1 equal seq2\n",
        "# seq1 = [1, 2, 3, 4, 0, 0, 0]\n",
        "# concat(seq1, seq2) [[1, 2, 3, 4, 0, 0, 0],\n",
        "#                     [9, 7, 6, 4, 3, 7, 5]]"
      ],
      "metadata": {
        "id": "0zXXXYP37gFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    data = []\n",
        "    target = []\n",
        "    for item in batch:\n",
        "        data.append(torch.as_tensor(item['data']))\n",
        "        target.append(torch.as_tensor(item['target']))\n",
        "    data = pad_sequence(data, batch_first=True, padding_value=0)\n",
        "    target = pad_sequence(target, batch_first=True, padding_value=0)\n",
        "\n",
        "    return {'data': data, 'target': target}"
      ],
      "metadata": {
        "id": "uPJauY4hAqJ6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GruPredictor(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes, bidirectional=False):\n",
        "        super().__init__()\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.mult_indx = 2 if bidirectional else 1\n",
        "\n",
        "        self.gru = nn.GRU(emb_dim, hidden_dim, batch_first=True, bidirectional=bidirectional)\n",
        "        self.classifier = nn.Linear(hidden_dim * self.mult_indx, n_classes)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.do = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.word_emb(x)\n",
        "        hidden, _ = self.gru(emb)\n",
        "\n",
        "        classes = self.classifier(self.do(hidden))\n",
        "\n",
        "        return classes"
      ],
      "metadata": {
        "id": "WBFZc1qY6HsC"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNPredictor(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes, bidirectional=False):\n",
        "        super().__init__()\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.mult_indx = 2 if bidirectional else 1\n",
        "\n",
        "        self.gru = nn.RNN(emb_dim, hidden_dim, batch_first=True, bidirectional=bidirectional)\n",
        "        self.classifier = nn.Linear(hidden_dim * self.mult_indx, n_classes)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.do = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.word_emb(x)\n",
        "        hidden, _ = self.gru(emb)\n",
        "\n",
        "        classes = self.classifier(self.do(hidden))\n",
        "\n",
        "        return classes"
      ],
      "metadata": {
        "id": "5oax-6dPIBl9"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LstmPredictor(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes, bidirectional=False):\n",
        "        super().__init__()\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.mult_indx = 2 if bidirectional else 1\n",
        "\n",
        "        self.gru = nn.LSTM(emb_dim, hidden_dim, batch_first=True, bidirectional=bidirectional)\n",
        "        self.classifier = nn.Linear(hidden_dim * self.mult_indx, n_classes)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.do = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.word_emb(x)\n",
        "        hidden, _ = self.gru(emb)\n",
        "\n",
        "        classes = self.classifier(self.do(hidden))\n",
        "\n",
        "        return classes"
      ],
      "metadata": {
        "id": "tkom0NA3ICOw"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T x B\n",
        "# len([[первые слова], [вторые слова], .. [последние слова]]) - длина предложения T\n",
        "# len([n-ые слова]) - размер батча B\n",
        "\n",
        "# B x T\n",
        "# len([[первое предложение], [второе предложение] .. ]) - размер батча B\n",
        "# len([первое предложение]) - длина предложения T"
      ],
      "metadata": {
        "id": "yLZvlyO69vR5"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyper params\n",
        "vocab_size = len(train_dataset.word_vocab) + 1\n",
        "n_classes = len(train_dataset.target_vocab) + 1\n",
        "n_chars = len(train_dataset.char_vocab) + 1\n",
        "\n",
        "emb_dim = 256\n",
        "hidden = 256\n",
        "n_epochs = 7\n",
        "batch_size = 64\n",
        "cuda_device = 0\n",
        "device = f'cuda:{cuda_device}' if cuda_device != -1 else 'cpu'"
      ],
      "metadata": {
        "id": "K_PACmDaH8Z7"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PredictorTrainer:\n",
        "\n",
        "  def __init__(self, model, name):\n",
        "    self.name = name\n",
        "    self.model = model\n",
        "    self.model.train()\n",
        "    self.optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    self.loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "  def train(self):\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "      train_loss = 0\n",
        "      test_loss = 0\n",
        "\n",
        "      train_dataloader = DataLoader(train_dataset,\n",
        "                              batch_size,\n",
        "                              shuffle=True,\n",
        "                              collate_fn=collate_fn,\n",
        "                              drop_last = True,\n",
        "                              )\n",
        "\n",
        "      train_loss += self._train_model(train_dataloader, self.model)\n",
        "\n",
        "\n",
        "      train_losses.append(train_loss / len(train_dataloader))\n",
        "\n",
        "      print(f'Epoch [{epoch+1}/{n_epochs}], '\n",
        "              f'Train Loss: {train_losses[-1]:.4f}, ')\n",
        "\n",
        "      torch.save(self.model.state_dict(), f'./{self.name}_chkpt_{epoch}.pth')\n",
        "    return sum(train_losses) / n_epochs\n",
        "\n",
        "  def _train_model(self, train_dataloader, model):\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "      self.optim.zero_grad()\n",
        "\n",
        "      predict = model(batch['data'].to(device))\n",
        "      loss = self.loss_func(predict.view(-1, n_classes),\n",
        "                        batch['target'].to(device).view(-1),\n",
        "                        )\n",
        "      loss.backward()\n",
        "      self.optim.step()\n",
        "\n",
        "      train_loss += loss.item()\n",
        "\n",
        "    return train_loss\n",
        "\n",
        "  def _validate_model(self, test_dataloader, model):\n",
        "    test_loss = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for i, batch in enumerate(test_dataloader):\n",
        "        predict = model(batch['data'].to(device))\n",
        "        target = batch['target'].to(device).long()\n",
        "\n",
        "        loss = self.loss_func(predict.view(-1, n_classes),\n",
        "                        batch['target'].to(device).view(-1),\n",
        "                        )\n",
        "\n",
        "        test_loss += loss.item()\n",
        "\n",
        "    return test_loss\n",
        "\n",
        "  def inference(self, dataset, phrase):\n",
        "    words = phrase.split(' ')\n",
        "    tokens = [dataset.word_vocab[w] for w in words]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        self.model.eval()\n",
        "        predict = self.model(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
        "        labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "\n",
        "    target_labels = list(dataset.target_vocab.keys())\n",
        "    print([target_labels[l-1] for l in labels])\n",
        "\n"
      ],
      "metadata": {
        "id": "9bMsBeqV8GCf"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_rnn = RNNPredictor(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
        "trainer_rnn = PredictorTrainer(model_rnn, 'RNN')\n",
        "\n",
        "model_lstm = LstmPredictor(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
        "trainer_lstm = PredictorTrainer(model_lstm, 'LSTM')\n",
        "\n",
        "model_gru = GruPredictor(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
        "trainer_gru = PredictorTrainer(model_gru, 'GRU')\n",
        "\n",
        "model_birnn = RNNPredictor(vocab_size, emb_dim, hidden, n_classes, True).to(device)\n",
        "trainer_birnn = PredictorTrainer(model_birnn, 'BiRNN')\n",
        "\n",
        "model_bilstm = LstmPredictor(vocab_size, emb_dim, hidden, n_classes, True).to(device)\n",
        "trainer_bilstm = PredictorTrainer(model_bilstm, 'BiLSTM')\n",
        "\n",
        "model_bigru = GruPredictor(vocab_size, emb_dim, hidden, n_classes, True).to(device)\n",
        "trainer_bigru = PredictorTrainer(model_bigru, 'BiGRU')"
      ],
      "metadata": {
        "id": "a4gX5zVDIZdu"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {\n",
        "    'модель': [],\n",
        "    'время обучения': [],\n",
        "    'loss на обучении': [],\n",
        "    'время инференса': []\n",
        "}\n",
        "\n",
        "phrase = 'He ran quickly after the red bus and caught it .'"
      ],
      "metadata": {
        "id": "JeAwZa7EXoR1"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainers = [trainer_rnn, trainer_lstm, trainer_gru, trainer_birnn, trainer_bilstm, trainer_bigru]\n",
        "\n",
        "for model_tr in trainers:\n",
        "  results['модель'].append(model_tr.name)\n",
        "  print(model_tr.name)\n",
        "\n",
        "  start = datetime.datetime.now()\n",
        "  loss = model_tr.train()\n",
        "  results['loss на обучении'].append(loss)\n",
        "\n",
        "  end = datetime.datetime.now() - start\n",
        "  results['время обучения'].append(end)\n",
        "\n",
        "  start = datetime.datetime.now()\n",
        "  model_tr.inference(train_dataset, phrase)\n",
        "  end = datetime.datetime.now() - start\n",
        "  results['время инференса'].append(end)\n",
        "\n",
        "  print('-' * 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lT4lZ7gbHrc3",
        "outputId": "834bd7ce-519d-449a-c8fc-5b53330b43eb"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN\n",
            "Epoch [1/7], Train Loss: 0.3516, \n",
            "Epoch [2/7], Train Loss: 0.1604, \n",
            "Epoch [3/7], Train Loss: 0.1206, \n",
            "Epoch [4/7], Train Loss: 0.0959, \n",
            "Epoch [5/7], Train Loss: 0.0791, \n",
            "Epoch [6/7], Train Loss: 0.0677, \n",
            "Epoch [7/7], Train Loss: 0.0593, \n",
            "['PRON', 'VERB', 'ADV', 'ADP', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'PRON', 'PUNCT']\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "LSTM\n",
            "Epoch [1/7], Train Loss: 0.4039, \n",
            "Epoch [2/7], Train Loss: 0.1601, \n",
            "Epoch [3/7], Train Loss: 0.1162, \n",
            "Epoch [4/7], Train Loss: 0.0899, \n",
            "Epoch [5/7], Train Loss: 0.0741, \n",
            "Epoch [6/7], Train Loss: 0.0612, \n",
            "Epoch [7/7], Train Loss: 0.0526, \n",
            "['PRON', 'VERB', 'ADV', 'ADP', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'PRON', 'PUNCT']\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "GRU\n",
            "Epoch [1/7], Train Loss: 0.3579, \n",
            "Epoch [2/7], Train Loss: 0.1518, \n",
            "Epoch [3/7], Train Loss: 0.1100, \n",
            "Epoch [4/7], Train Loss: 0.0881, \n",
            "Epoch [5/7], Train Loss: 0.0723, \n",
            "Epoch [6/7], Train Loss: 0.0601, \n",
            "Epoch [7/7], Train Loss: 0.0511, \n",
            "['PRON', 'VERB', 'ADV', 'SCONJ', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'PRON', 'PUNCT']\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "BiRNN\n",
            "Epoch [1/7], Train Loss: 0.2988, \n",
            "Epoch [2/7], Train Loss: 0.1305, \n",
            "Epoch [3/7], Train Loss: 0.0939, \n",
            "Epoch [4/7], Train Loss: 0.0721, \n",
            "Epoch [5/7], Train Loss: 0.0576, \n",
            "Epoch [6/7], Train Loss: 0.0468, \n",
            "Epoch [7/7], Train Loss: 0.0380, \n",
            "['PRON', 'VERB', 'ADV', 'ADP', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'PRON', 'PUNCT']\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "BiLSTM\n",
            "Epoch [1/7], Train Loss: 0.3326, \n",
            "Epoch [2/7], Train Loss: 0.1197, \n",
            "Epoch [3/7], Train Loss: 0.0813, \n",
            "Epoch [4/7], Train Loss: 0.0604, \n",
            "Epoch [5/7], Train Loss: 0.0458, \n",
            "Epoch [6/7], Train Loss: 0.0348, \n",
            "Epoch [7/7], Train Loss: 0.0258, \n",
            "['PRON', 'VERB', 'ADV', 'ADP', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'PRON', 'PUNCT']\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "BiGRU\n",
            "Epoch [1/7], Train Loss: 0.2993, \n",
            "Epoch [2/7], Train Loss: 0.1145, \n",
            "Epoch [3/7], Train Loss: 0.0786, \n",
            "Epoch [4/7], Train Loss: 0.0573, \n",
            "Epoch [5/7], Train Loss: 0.0441, \n",
            "Epoch [6/7], Train Loss: 0.0329, \n",
            "Epoch [7/7], Train Loss: 0.0248, \n",
            "['PRON', 'VERB', 'ADV', 'ADP', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'PRON', 'PUNCT']\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "9PbgCjN48FRe"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "74gggSX58Fe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "d8804d54-46b3-4fe4-a8b8-78495e45afd7"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   модель         время обучения  loss на обучении        время инференса\n",
              "0     RNN 0 days 00:00:14.705274          0.133505 0 days 00:00:00.002221\n",
              "1    LSTM 0 days 00:00:22.074058          0.136864 0 days 00:00:00.001586\n",
              "2     GRU 0 days 00:00:20.314892          0.127346 0 days 00:00:00.002140\n",
              "3   BiRNN 0 days 00:00:18.286657          0.105393 0 days 00:00:00.002161\n",
              "4  BiLSTM 0 days 00:00:35.735210          0.100034 0 days 00:00:00.001994\n",
              "5   BiGRU 0 days 00:00:30.755490          0.093083 0 days 00:00:00.003159"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-982fc4e1-ab4a-47e6-9b63-768e00b54d03\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>модель</th>\n",
              "      <th>время обучения</th>\n",
              "      <th>loss на обучении</th>\n",
              "      <th>время инференса</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RNN</td>\n",
              "      <td>0 days 00:00:14.705274</td>\n",
              "      <td>0.133505</td>\n",
              "      <td>0 days 00:00:00.002221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>0 days 00:00:22.074058</td>\n",
              "      <td>0.136864</td>\n",
              "      <td>0 days 00:00:00.001586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GRU</td>\n",
              "      <td>0 days 00:00:20.314892</td>\n",
              "      <td>0.127346</td>\n",
              "      <td>0 days 00:00:00.002140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BiRNN</td>\n",
              "      <td>0 days 00:00:18.286657</td>\n",
              "      <td>0.105393</td>\n",
              "      <td>0 days 00:00:00.002161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BiLSTM</td>\n",
              "      <td>0 days 00:00:35.735210</td>\n",
              "      <td>0.100034</td>\n",
              "      <td>0 days 00:00:00.001994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>BiGRU</td>\n",
              "      <td>0 days 00:00:30.755490</td>\n",
              "      <td>0.093083</td>\n",
              "      <td>0 days 00:00:00.003159</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-982fc4e1-ab4a-47e6-9b63-768e00b54d03')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-982fc4e1-ab4a-47e6-9b63-768e00b54d03 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-982fc4e1-ab4a-47e6-9b63-768e00b54d03');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4c065365-ddce-4ca5-aa74-81bb8567994f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4c065365-ddce-4ca5-aa74-81bb8567994f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4c065365-ddce-4ca5-aa74-81bb8567994f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"\\u043c\\u043e\\u0434\\u0435\\u043b\\u044c\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"RNN\",\n          \"LSTM\",\n          \"BiGRU\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0432\\u0440\\u0435\\u043c\\u044f \\u043e\\u0431\\u0443\\u0447\\u0435\\u043d\\u0438\\u044f\",\n      \"properties\": {\n        \"dtype\": \"timedelta64[ns]\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"0 days 00:00:14.705274\",\n          \"0 days 00:00:22.074058\",\n          \"0 days 00:00:30.755490\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loss \\u043d\\u0430 \\u043e\\u0431\\u0443\\u0447\\u0435\\u043d\\u0438\\u0438\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01877777350123762,\n        \"min\": 0.09308334325962372,\n        \"max\": 0.13686401514597538,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.13350492242517856,\n          0.13686401514597538,\n          0.09308334325962372\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0432\\u0440\\u0435\\u043c\\u044f \\u0438\\u043d\\u0444\\u0435\\u0440\\u0435\\u043d\\u0441\\u0430\",\n      \"properties\": {\n        \"dtype\": \"timedelta64[ns]\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"0 days 00:00:00.002221\",\n          \"0 days 00:00:00.001586\",\n          \"0 days 00:00:00.003159\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Вывод - модель RNN работает быстрее всех, но loss на обучении чуть выше LSTM и GRU. LSTM дольше всех, но loss как у gru. Bidirectional работает дольше во всех моделях, loss при этом также лучше. На инференсе не ошиблась только GRU.*"
      ],
      "metadata": {
        "id": "b5ZZzzsjd6tW"
      }
    }
  ]
}